import os
import sys
import logging
import datasets
import evaluate

import pandas as pd
import numpy as np
import torch  # ç¡®ä¿å¯¼å…¥äº† torch

# ç§»é™¤äº†é‡å¤çš„ AutoModelForSequenceClassification å¯¼å…¥
from transformers import AutoModelForSequenceClassification, DebertaV2Tokenizer, DataCollatorWithPadding
from transformers import BitsAndBytesConfig, Trainer, TrainingArguments
from peft import PromptEncoderConfig, get_peft_model, TaskType
from sklearn.model_selection import train_test_split

# --- 1. åŠ è½½æ•°æ® (è¿™éƒ¨åˆ†ä¸å˜) ---
train = pd.read_csv("/kaggle/input/labeledtraindata-tsv/labeledTrainData.tsv", header=0, delimiter="\t", quoting=3)
test = pd.read_csv("/kaggle/input/testdata-tsv/testData.tsv", header=0, delimiter="\t", quoting=3)

if __name__ == '__main__':
    program = os.path.basename(sys.argv[0])
    logger = logging.getLogger(program)

    logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s')
    logging.root.setLevel(level=logging.INFO)
    logger.info(r"running %s" % ''.join(sys.argv))

    # --- 2. æ•°æ®é›†å‡†å¤‡ (è¿™éƒ¨åˆ†ä¸å˜) ---
    train, val = train_test_split(train, test_size=.2)

    train_dict = {'label': train["sentiment"], 'text': train['review']}
    val_dict = {'label': val["sentiment"], 'text': val['review']}
    test_dict = {"text": test['review']}

    train_dataset = datasets.Dataset.from_dict(train_dict)
    val_dataset = datasets.Dataset.from_dict(val_dict)
    test_dataset = datasets.Dataset.from_dict(test_dict)

    # --- 3. Tokenizer å’Œæ•°æ®å¤„ç† (è¿™éƒ¨åˆ†ä¸å˜) ---
    model_id = "microsoft/deberta-v3-base"
    tokenizer = DebertaV2Tokenizer.from_pretrained(model_id)


    def preprocess_function(examples):
        return tokenizer(examples['text'], max_length=256, truncation=True)


    tokenized_train = train_dataset.map(preprocess_function, batched=True)
    tokenized_val = val_dataset.map(preprocess_function, batched=True)
    tokenized_test = test_dataset.map(preprocess_function, batched=True)

    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

    # --- 4. æ¨¡å‹åŠ è½½å’Œ PEFT (## --- è¿™é‡Œæ˜¯ä¸»è¦ä¿®å¤ ---) ---

    # B. åŠ è½½é‡åŒ–åçš„åŸºç¡€æ¨¡å‹ (åªåŠ è½½ä¸€æ¬¡)
    model = AutoModelForSequenceClassification.from_pretrained(
        model_id,
        torch_dtype=torch.float16,
        device_map="auto"  # ä½¿ç”¨8-bitæ—¶ï¼Œå¼ºçƒˆæ¨èä½¿ç”¨ "auto"
    )

    # C. å®šä¹‰ P-Tuning é…ç½®
    peft_config = PromptEncoderConfig(
        num_virtual_tokens=20,
        encoder_hidden_size=128,
        task_type=TaskType.SEQ_CLS
    )

    # D. (## --- ä¿®å¤: åº”ç”¨ PEFT é…ç½® ---)
    #    æˆ‘ä»¬ç”¨ peft_config åŒ…è£… 'model'ï¼Œå¹¶æŠŠç»“æœå­˜å› 'model' å˜é‡ä¸­
    model = get_peft_model(model, peft_config)

    # E. (## --- ä¿®å¤: ç°åœ¨åœ¨ PEFT æ¨¡å‹ä¸Šè°ƒç”¨ ---)
    #    è¿™å°†æ˜¾ç¤ºåªæœ‰ä¸€å°éƒ¨åˆ†å‚æ•°æ˜¯å¯è®­ç»ƒçš„ (P-Tuning è™šæ‹Ÿ token)
    model.print_trainable_parameters()

    # --- 5. è®­ç»ƒå™¨è®¾ç½® (Metrics å’Œ TrainingArguments ä¸å˜) ---
    metric = evaluate.load("accuracy")


    def compute_metrics(eval_pred):
        logits, labels = eval_pred
        predictions = np.argmax(logits, axis=-1)
        return metric.compute(predictions=predictions, references=labels)


    training_args = TrainingArguments(
        output_dir='./checkpoint',  # output directory
        num_train_epochs=3,  # total number of training epochs
        per_device_train_batch_size=2,  # batch size per device during training
        per_device_eval_batch_size=4,  # batch size for evaluation
        warmup_steps=500,  # number of warmup steps for learning rate scheduler
        weight_decay=0.01,  # strength of weight decay
        fp16=True,
        logging_dir='./logs',  # directory for storing logs
        logging_steps=10,
        report_to="none",
        save_strategy="no",
        eval_strategy="epoch"
    )

    # --- 6. è®­ç»ƒå™¨åˆå§‹åŒ– (## --- å…³é”® ---) ---
    #    ç°åœ¨ 'model' å˜é‡æ˜¯ PEFT åŒ…è£…è¿‡çš„æ¨¡å‹
    #    Trainer å°†åªè®­ç»ƒ P-Tuning çš„å‚æ•°
    trainer = Trainer(
        model=model,  # the instantiated ğŸ¤— Transformers model to be trained
        args=training_args,  # training arguments, defined above
        train_dataset=tokenized_train,  # training dataset
        eval_dataset=tokenized_val,  # evaluation dataset
        tokenizer=tokenizer,
        data_collator=data_collator,
        compute_metrics=compute_metrics,
    )

    # --- 7. è®­ç»ƒå’Œé¢„æµ‹ (è¿™éƒ¨åˆ†ä¸å˜) ---
    trainer.train()

    prediction_outputs = trainer.predict(tokenized_test)
    test_pred = np.argmax(prediction_outputs[0], axis=-1).flatten()
    print(test_pred)

    # --- 8. ä¿å­˜ç»“æœ (## --- ä¿®å¤: æ·»åŠ äº†æ–‡ä»¶å¤¹åˆ›å»ºå’Œé‡å‘½å ---) ---

    # (## --- ä¿®å¤: ç¡®ä¿ ./result æ–‡ä»¶å¤¹å­˜åœ¨ ---)
    os.makedirs("./result", exist_ok=True)

    result_output = pd.DataFrame(data={"id": test["id"], "sentiment": test_pred})

    # (## --- ä¿®å¤: é‡å‘½åæ–‡ä»¶ä»¥åŒ¹é… "ptuning" ---)
    output_csv_path = "./result/deberta_ptuning_int8.csv"
    result_output.to_csv(output_csv_path, index=False, quoting=3)

    logging.info(f'result saved to {output_csv_path}!')