{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13516256,"sourceType":"datasetVersion","datasetId":8581792}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom transformers import pipeline\nfrom torch.utils.data import Dataset\nfrom tqdm.auto import tqdm\nimport re\n\n# --- 1. 读取数据 ---\ntry:\n    df = pd.read_csv('/kaggle/input/testdata-tsv/testData.tsv', sep='\\t')\nexcept:\n    df = pd.DataFrame({'id': range(5), 'review': [\"This movie is fantastic!\"]*5})\n\n# --- 2. 定义 Dataset ---\nclass ReviewDataset(Dataset):\n    def __init__(self, texts):\n        self.texts = texts\n    def __len__(self):\n        return len(self.texts)\n    def __getitem__(self, idx):\n        return self.texts[idx]\n\n# --- 3. 核心修改：Few-Shot Prompt (少样本提示) ---\n# 我们在 Prompt 里直接给出 3 个例子 (2正1负)，并不加 <think> 标签\n# 这样模型会模仿上面的格式，直接输出 0 或 1\nfew_shot_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nAnalyze the IMDb movie review and determine the sentiment polarity.\nReturn 1 for positive, 0 for negative. Output ONLY the number.\n\n### Input:\nI loved this movie! It was fantastic and the acting was great.\n### Response:\n1\n\n### Input:\nThis was the worst film I have ever seen. Boring and terrible plot.\n### Response:\n0\n\n### Input:\nA masterpiece of cinema, truly touching and beautiful.\n### Response:\n1\n\n### Input:\n{review_text}\n### Response:\n\"\"\"\n\n# 预处理：因为Prompt变长了，我们把Input截断得稍微短一点 (1000字符) 留给上下文\nformatted_prompts = [few_shot_prompt.format(review_text=str(text)[:1000]) for text in df['review']]\ndataset = ReviewDataset(formatted_prompts)\n\n# --- 4. 加载模型 (1.5B) ---\nmodel_id = \"Qwen/Qwen2.5-3B-Instruct\"\n\nprint(\"正在加载模型...\")\npipe = pipeline(\n    \"text-generation\",\n    model=model_id,\n    device=0,                   # 使用 GPU\n    torch_dtype=torch.float16,  # T4 显卡优化\n    max_new_tokens=20,          # <--- 关键！只允许生成 10 个 token，逼迫它直接给结果\n    truncation=True\n)\n\n# 消除警告\npipe.tokenizer.pad_token_id = pipe.tokenizer.eos_token_id\npipe.tokenizer.padding_side = 'left'\n\n# --- 5. 执行推理 ---\n# 因为只生成 1 个数字，速度会飞快，Batch Size 可以拉满\nBATCH_SIZE = 128\nresults = []\n\nprint(f\"开始极速直出推理 (Batch Size={BATCH_SIZE})...\")\n\nfor i, out in enumerate(tqdm(pipe(dataset, batch_size=BATCH_SIZE), total=len(dataset))):\n    text = out[0]['generated_text']\n    \n    # --- 6. 极简解析 ---\n    # 不需要切分 <think> 了，直接看最后生成了什么\n    # 取 prompt 之后生成的部分\n    generated_part = text[len(formatted_prompts[i]):] \n    \n    # 找里面的 0 或 1\n    match = re.search(r'\\b(0|1)\\b', generated_part)\n    if match:\n        pred = int(match.group(1))\n    else:\n        # 兜底：如果没找到数字，看关键词\n        pred = 0 if \"negative\" in generated_part.lower() or \"boring\" in generated_part.lower() else 1\n    \n    results.append(pred)\n    \n    # Debug: 打印前3条验证是否真的跳过了思考\n    if i < 3:\n        print(f\"\\n--- Sample {i} ---\")\n        print(f\"Generated: {generated_part.strip()}\") \n        print(f\"Predicted: {pred}\")\n\n# --- 7. 保存 ---\ndf['sentiment'] = results\ndf[['id', 'sentiment']].to_csv('Llama.csv', index=False)\nprint(\"\\n任务完成！\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T11:37:28.745874Z","iopub.execute_input":"2025-11-25T11:37:28.746141Z","iopub.status.idle":"2025-11-25T13:11:15.493694Z","shell.execute_reply.started":"2025-11-25T11:37:28.746121Z","shell.execute_reply":"2025-11-25T13:11:15.492835Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"正在加载模型...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/661 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a092d0af2fdf47939c31d3c72da76862"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b955509f75643f6be443c702598811d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef515482807343e3ba2cce8b50c02908"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3fc3ba0b2964baba4991262d6db7aac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c64e8c184b2a4214ba40aba67e70f616"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d7a4366056641fdb1d06cc3c10c99cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d090d35569745aba5cd50f081b4c7c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebaeae18c5a94dcfbb45f9d45490ffde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b188f42e72e49ff801358d9a3cba87b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebbbeb29f2d9490b97e0aa18bb32b301"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"331540dc1f1e4556b7cdc711caa6316a"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"开始极速直出推理 (Batch Size=128)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86710ba0d1404ce59d2d2c96577137e8"}},"metadata":{}},{"name":"stdout","text":"\n--- Sample 0 ---\nGenerated: 1\n\n### Input:\nThe acting was wooden and the plot was convoluted and hard to follow\nPredicted: 1\n\n--- Sample 1 ---\nGenerated: 0\n\nThe input contains both positive and negative sentiments, but the overall tone leans towards negative due to\nPredicted: 0\n\n--- Sample 2 ---\nGenerated: 1\n\n### Input:\nThe plot was confusing, the acting was subpar, and the special effects\nPredicted: 1\n\n任务完成！\n","output_type":"stream"}],"execution_count":2}]}