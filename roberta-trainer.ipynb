{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13406191,"sourceType":"datasetVersion","datasetId":8508005},{"sourceId":13516246,"sourceType":"datasetVersion","datasetId":8581788},{"sourceId":13516256,"sourceType":"datasetVersion","datasetId":8581792}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport logging\nimport datasets\n\nimport pandas as pd\nimport numpy as np\n\nfrom transformers import RobertaTokenizerFast, RobertaForSequenceClassification, DataCollatorWithPadding\nfrom transformers import Trainer, TrainingArguments\nfrom sklearn.model_selection import train_test_split\n\ntrain = pd.read_csv(\"/kaggle/input/labeledtraindata-tsv/labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\ntest = pd.read_csv(\"/kaggle/input/testdata-tsv/testData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n\nif __name__ == '__main__':\n    program = os.path.basename(sys.argv[0])\n    logger = logging.getLogger(program)\n\n    logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s')\n    logging.root.setLevel(level=logging.INFO)\n    logger.info(r\"running %s\" % ''.join(sys.argv))\n\n    train, val = train_test_split(train, test_size=.2)\n\n    train_dict = {'label': train[\"sentiment\"], 'text': train['review']}\n    val_dict = {'label': val[\"sentiment\"], 'text': val['review']}\n    test_dict = {\"text\": test['review']}\n\n    train_dataset = datasets.Dataset.from_dict(train_dict)\n    val_dataset = datasets.Dataset.from_dict(val_dict)\n    test_dataset = datasets.Dataset.from_dict(test_dict)\n\n    tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n\n\n    def preprocess_function(examples):\n        return tokenizer(examples['text'], truncation=True)\n\n    tokenized_train = train_dataset.map(preprocess_function, batched=True)\n    tokenized_val = val_dataset.map(preprocess_function, batched=True)\n    tokenized_test = test_dataset.map(preprocess_function, batched=True)\n\n    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n    model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n\n    metric = datasets.load_metric(\"accuracy\")\n\n    def compute_metrics(eval_pred):\n        logits, labels = eval_pred\n        predictions = np.argmax(logits, axis=-1)\n        return metric.compute(predictions=predictions, references=labels)\n\n\n    training_args = TrainingArguments(\n        output_dir='./results',  # output directory\n        num_train_epochs=3,  # total number of training epochs\n        per_device_train_batch_size=4,  # batch size per device during training\n        per_device_eval_batch_size=8,  # batch size for evaluation\n        learning_rate=5e-6,\n        warmup_steps=500,  # number of warmup steps for learning rate scheduler\n        weight_decay=0.01,  # strength of weight decay\n        logging_dir='./logs',  # directory for storing logs\n        logging_steps=100,\n        save_strategy=\"no\",\n        report_to=\"none\",\n        eval_strategy=\"epoch\"\n    )\n\n    trainer = Trainer(\n        model=model,  # the instantiated ðŸ¤— Transformers model to be trained\n        args=training_args,  # training arguments, defined above\n        train_dataset=tokenized_train,  # training dataset\n        eval_dataset=tokenized_val,  # evaluation dataset\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics,\n    )\n\n    trainer.train()\n\n    prediction_outputs = trainer.predict(tokenized_test)\n    test_pred = np.argmax(prediction_outputs[0], axis=-1).flatten()\n    print(test_pred)\n\n    os.makedirs(\"./result\", exist_ok=True)\n    \n    result_output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred})\n    result_output.to_csv(\"./result/roberta_trainer.csv\", index=False, quoting=3)\n    logging.info('result saved!')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}