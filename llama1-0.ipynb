{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13516256,"sourceType":"datasetVersion","datasetId":8581792}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom transformers import pipeline\nfrom torch.utils.data import Dataset\nfrom tqdm.auto import tqdm\nimport re\n\n# --- 1. 读取数据 ---\ntry:\n    df = pd.read_csv('/kaggle/input/testdata-tsv/testData.tsv', sep='\\t')\nexcept:\n    df = pd.DataFrame({'id': range(5), 'review': [\"This movie is fantastic!\"]*5})\n\n# --- 2. 定义 Dataset ---\nclass ReviewDataset(Dataset):\n    def __init__(self, texts):\n        self.texts = texts\n    def __len__(self):\n        return len(self.texts)\n    def __getitem__(self, idx):\n        return self.texts[idx]\n\n# --- 3. 核心修改：Few-Shot Prompt (少样本提示) ---\n# 我们在 Prompt 里直接给出 3 个例子 (2正1负)，并不加 <think> 标签\n# 这样模型会模仿上面的格式，直接输出 0 或 1\nfew_shot_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nAnalyze the IMDb movie review and determine the sentiment polarity.\nReturn 1 for positive, 0 for negative. Output ONLY the number.\n\n### Input:\nI loved this movie! It was fantastic and the acting was great.\n### Response:\n1\n\n### Input:\nThis was the worst film I have ever seen. Boring and terrible plot.\n### Response:\n0\n\n### Input:\nA masterpiece of cinema, truly touching and beautiful.\n### Response:\n1\n\n### Input:\n{review_text}\n### Response:\n\"\"\"\n\n# 预处理：因为Prompt变长了，我们把Input截断得稍微短一点 (1000字符) 留给上下文\nformatted_prompts = [few_shot_prompt.format(review_text=str(text)[:1000]) for text in df['review']]\ndataset = ReviewDataset(formatted_prompts)\n\n# --- 4. 加载模型 (1.5B) ---\nmodel_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n\nprint(\"正在加载模型...\")\npipe = pipeline(\n    \"text-generation\",\n    model=model_id,\n    device=0,                   # 使用 GPU\n    torch_dtype=torch.float16,  # T4 显卡优化\n    max_new_tokens=20,          # <--- 关键！只允许生成 10 个 token，逼迫它直接给结果\n    truncation=True\n)\n\n# 消除警告\npipe.tokenizer.pad_token_id = pipe.tokenizer.eos_token_id\npipe.tokenizer.padding_side = 'left'\n\n# --- 5. 执行推理 ---\n# 因为只生成 1 个数字，速度会飞快，Batch Size 可以拉满\nBATCH_SIZE = 128\nresults = []\n\nprint(f\"开始极速直出推理 (Batch Size={BATCH_SIZE})...\")\n\nfor i, out in enumerate(tqdm(pipe(dataset, batch_size=BATCH_SIZE), total=len(dataset))):\n    text = out[0]['generated_text']\n    \n    # --- 6. 极简解析 ---\n    # 不需要切分 <think> 了，直接看最后生成了什么\n    # 取 prompt 之后生成的部分\n    generated_part = text[len(formatted_prompts[i]):] \n    \n    # 找里面的 0 或 1\n    match = re.search(r'\\b(0|1)\\b', generated_part)\n    if match:\n        pred = int(match.group(1))\n    else:\n        # 兜底：如果没找到数字，看关键词\n        pred = 0 if \"negative\" in generated_part.lower() or \"boring\" in generated_part.lower() else 1\n    \n    results.append(pred)\n    \n    # Debug: 打印前3条验证是否真的跳过了思考\n    if i < 3:\n        print(f\"\\n--- Sample {i} ---\")\n        print(f\"Generated: {generated_part.strip()}\") \n        print(f\"Predicted: {pred}\")\n\n# --- 7. 保存 ---\ndf['sentiment'] = results\ndf[['id', 'sentiment']].to_csv('Llama.csv', index=False)\nprint(\"\\n任务完成！\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T10:42:43.805640Z","iopub.execute_input":"2025-11-25T10:42:43.806480Z","iopub.status.idle":"2025-11-25T11:29:49.221040Z","shell.execute_reply.started":"2025-11-25T10:42:43.806440Z","shell.execute_reply":"2025-11-25T11:29:49.220348Z"}},"outputs":[{"name":"stdout","text":"正在加载模型...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21f527d4a9694bb58d1ebc3b4b27744e"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44db610bd4b94570911db34b7f942072"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e106bdabd99c4dee9e39b7e237e44c77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30035eefcea348a0b7734890bc7e5f94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"866fb03071f64f5b8c6f90f026bb623f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f8633a981fb4391b50ff9861cff68e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a16b188a15224c14985cb6ac91dbf700"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"开始极速直出推理 (Batch Size=128)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c92901f0f154189b5832bb711f69e73"}},"metadata":{}},{"name":"stdout","text":"\n--- Sample 0 ---\nGenerated: 1\nPredicted: 1\n\n--- Sample 1 ---\nGenerated: 0\n\nAs you see, the task was correctly completed. The given input provided the prompt for\nPredicted: 0\n\n--- Sample 2 ---\nGenerated: 1\nPredicted: 1\n\n任务完成！\n","output_type":"stream"}],"execution_count":3}]}