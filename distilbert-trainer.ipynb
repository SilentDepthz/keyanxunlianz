{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13406191,"sourceType":"datasetVersion","datasetId":8508005},{"sourceId":13516246,"sourceType":"datasetVersion","datasetId":8581788},{"sourceId":13516256,"sourceType":"datasetVersion","datasetId":8581792}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport logging\nimport datasets\n\nimport pandas as pd\nimport numpy as np\n\nfrom transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, DataCollatorWithPadding\nfrom transformers import Trainer, TrainingArguments\nfrom sklearn.model_selection import train_test_split\n\ntrain = pd.read_csv(\"/kaggle/input/labeledtraindata-tsv/labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\ntest = pd.read_csv(\"/kaggle/input/testdata-tsv/testData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n\nif __name__ == '__main__':\n    program = os.path.basename(sys.argv[0])\n    logger = logging.getLogger(program)\n\n    logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s')\n    logging.root.setLevel(level=logging.INFO)\n    logger.info(r\"running %s\" % ''.join(sys.argv))\n\n    train, val = train_test_split(train, test_size=.2)\n\n    train_dict = {'label': train[\"sentiment\"], 'text': train['review']}\n    val_dict = {'label': val[\"sentiment\"], 'text': val['review']}\n    test_dict = {\"text\": test['review']}\n\n    train_dataset = datasets.Dataset.from_dict(train_dict)\n    val_dataset = datasets.Dataset.from_dict(val_dict)\n    test_dataset = datasets.Dataset.from_dict(test_dict)\n\n    tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n\n\n    def preprocess_function(examples):\n        return tokenizer(examples['text'], truncation=True)\n\n    tokenized_train = train_dataset.map(preprocess_function, batched=True)\n    tokenized_val = val_dataset.map(preprocess_function, batched=True)\n    tokenized_test = test_dataset.map(preprocess_function, batched=True)\n\n    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n\n    metric = datasets.load_metric(\"accuracy\")\n\n    def compute_metrics(eval_pred):\n        logits, labels = eval_pred\n        predictions = np.argmax(logits, axis=-1)\n        return metric.compute(predictions=predictions, references=labels)\n\n\n    training_args = TrainingArguments(\n        output_dir='./results',  # output directory\n        num_train_epochs=3,  # total number of training epochs\n        per_device_train_batch_size=12,  # batch size per device during training\n        per_device_eval_batch_size=24,  # batch size for evaluation\n        warmup_steps=500,  # number of warmup steps for learning rate scheduler\n        weight_decay=0.01,  # strength of weight decay\n        logging_dir='./logs',  # directory for storing logs\n        logging_steps=100,\n        save_strategy=\"no\",\n        report_to=\"none\",\n        eval_strategy=\"epoch\"\n    )\n\n    trainer = Trainer(\n        model=model,  # the instantiated ðŸ¤— Transformers model to be trained\n        args=training_args,  # training arguments, defined above\n        train_dataset=tokenized_train,  # training dataset\n        eval_dataset=tokenized_val,  # evaluation dataset\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics,\n    )\n\n    trainer.train()\n\n    prediction_outputs = trainer.predict(tokenized_test)\n    test_pred = np.argmax(prediction_outputs[0], axis=-1).flatten()\n    print(test_pred)\n\n    os.makedirs(\"./result\", exist_ok=True)\n    \n    result_output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred})\n    result_output.to_csv(\"./result/distilbert_trainer.csv\", index=False, quoting=3)\n    logging.info('result saved!')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T12:48:19.104693Z","iopub.execute_input":"2025-11-15T12:48:19.105409Z"}},"outputs":[{"name":"stderr","text":"2025-11-15 12:48:36.901695: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763210917.156326      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763210917.230222      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stderr","text":"INFO:colab_kernel_launcher.py:running /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py-f/root/.local/share/jupyter/runtime/kernel-632a96ed-0b8e-457e-bb18-ee89d650271e.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8311c6a201864003874eb4e0f16bdce8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"294b394ee717471ea5f65a75403810d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7acb44cfe809440e922e053fa96ebb98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d826a03b83a74a5e99d9b4caf033e065"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d89c917a3db24c5b8ad24068ca22f21e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4d39b01305e41af8b2c2c38dd8d8104"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed11a6caf31a49b3b9b17299cdadbf8c"}},"metadata":{}}],"execution_count":null}]}