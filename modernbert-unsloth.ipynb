{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13406191,"sourceType":"datasetVersion","datasetId":8508005},{"sourceId":13516246,"sourceType":"datasetVersion","datasetId":8581788},{"sourceId":13516256,"sourceType":"datasetVersion","datasetId":8581792}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T02:38:30.874122Z","iopub.execute_input":"2025-11-19T02:38:30.874807Z","iopub.status.idle":"2025-11-19T02:38:34.900374Z","shell.execute_reply.started":"2025-11-19T02:38:30.874777Z","shell.execute_reply":"2025-11-19T02:38:34.899399Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.3.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.9.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.6\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"pip install unsloth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T02:32:52.608960Z","iopub.execute_input":"2025-11-19T02:32:52.609749Z","iopub.status.idle":"2025-11-19T02:37:22.241322Z","shell.execute_reply.started":"2025-11-19T02:32:52.609722Z","shell.execute_reply":"2025-11-19T02:37:22.240557Z"}},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.11.3-py3-none-any.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth_zoo>=2025.11.4 (from unsloth)\n  Downloading unsloth_zoo-2025.11.4-py3-none-any.whl.metadata (32 kB)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth) (25.0)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.21.0+cu124)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.26.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (7.1.3)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.35-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from unsloth) (6.33.0)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.33.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\nCollecting bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 (from unsloth)\n  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.2.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\nCollecting datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 (from unsloth)\n  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.9.0)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.16.0)\nRequirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.36.0)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.34.0)\nRequirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.53.3)\nCollecting trl!=0.19.0,<=0.23.0,>=0.18.2 (from unsloth)\n  Downloading trl-0.23.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.3)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.20.0)\nCollecting pyarrow>=21.0.0 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\nCollecting multiprocess<0.70.17 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\nCollecting fsspec<=2025.9.0,>=2023.1.0 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth) (2025.11.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth) (0.21.2)\nCollecting transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3 (from unsloth)\n  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.2,>=4.51.3->unsloth)\n  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting torchao>=0.13.0 (from unsloth_zoo>=2025.11.4->unsloth)\n  Downloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.11.4->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.11.4->unsloth) (11.3.0)\nCollecting msgspec (from unsloth_zoo>=2025.11.4->unsloth)\n  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\nCollecting sympy>=1.13.3 (from torch>=2.4.0->unsloth)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\nCollecting nvidia-nccl-cu12==2.27.5 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvshmem-cu12==3.3.20 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\nCollecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.7.0)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.24.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n  Downloading torchvision-0.24.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.17.0)\nRequirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (14.2.0)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.8.0-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.4)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.16.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.5.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.22.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.17.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.3.1)\nDownloading unsloth-2025.11.3-py3-none-any.whl (353 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.0/353.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading datasets-4.3.0-py3-none-any.whl (506 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.23.0-py3-none-any.whl (564 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.7/564.7 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.11.4-py3-none-any.whl (283 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.5/283.5 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.33.post1-cp39-abi3-manylinux_2_28_x86_64.whl (122.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl (899.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-3.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.4/170.4 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchvision-0.24.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading tyro-0.9.35-py3-none-any.whl (132 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading shtab-1.8.0-py3-none-any.whl (14 kB)\nDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m229.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torchao, nvidia-cusparselt-cu12, triton, sympy, shtab, pyarrow, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multiprocess, msgspec, fsspec, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, tyro, tokenizers, nvidia-cusolver-cu12, torch, cut_cross_entropy, transformers, datasets, trl, xformers, unsloth_zoo, torchvision, bitsandbytes, unsloth\n  Attempting uninstall: torchao\n    Found existing installation: torchao 0.10.0\n    Uninstalling torchao-0.10.0:\n      Successfully uninstalled torchao-0.10.0\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.18\n    Uninstalling multiprocess-0.70.18:\n      Successfully uninstalled multiprocess-0.70.18\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.10.0\n    Uninstalling fsspec-2025.10.0:\n      Successfully uninstalled fsspec-2025.10.0\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\n  Attempting uninstall: datasets\n    Found existing installation: datasets 4.4.1\n    Uninstalling datasets-4.4.1:\n      Successfully uninstalled datasets-4.4.1\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.21.0+cu124\n    Uninstalling torchvision-0.21.0+cu124:\n      Successfully uninstalled torchvision-0.21.0+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ns3fs 2025.3.0 requires fsspec==2025.3.0.*, but you have fsspec 2025.9.0 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.9.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.48.2 cut_cross_entropy-25.1.1 datasets-4.3.0 fsspec-2025.9.0 msgspec-0.19.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 pyarrow-22.0.0 shtab-1.8.0 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.0 torchao-0.14.1 torchvision-0.24.0 transformers-4.57.1 triton-3.5.0 trl-0.23.0 tyro-0.9.35 unsloth-2025.11.3 unsloth_zoo-2025.11.4 xformers-0.0.33.post1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\n\nos.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n\nimport unsloth\nimport torch\nimport sys\nimport logging\nimport evaluate\n\nimport pandas as pd\nimport numpy as np\n\nfrom unsloth import FastModel, FastLanguageModel\nfrom transformers import TrainingArguments, Trainer, AutoModelForSequenceClassification, training_args, \\\n    DataCollatorWithPadding\nfrom datasets import Dataset\n\nfrom sklearn.model_selection import train_test_split\n\ntrain = pd.read_csv(\"/kaggle/input/labeledtraindata-tsv/labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\ntest = pd.read_csv(\"/kaggle/input/testdata-tsv/testData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n\nif __name__ == '__main__':\n    program = os.path.basename(sys.argv[0])\n    logger = logging.getLogger(program)\n\n    logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s')\n    logging.root.setLevel(level=logging.INFO)\n    logger.info(r\"running %s\" % ''.join(sys.argv))\n\n    train, val = train_test_split(train, test_size=.2)\n\n    #train = train[0:20]\n    #val = val[0:20]\n    #test = test[0:20]\n\n    train_dict = {'label': train[\"sentiment\"], 'text': train['review']}\n    val_dict = {'label': val[\"sentiment\"], 'text': val['review']}\n    test_dict = {\"text\": test['review']}\n\n    train_dataset = Dataset.from_dict(train_dict)\n    val_dataset = Dataset.from_dict(val_dict)\n    test_dataset = Dataset.from_dict(test_dict)\n\n    model_name = 'answerdotai/ModernBERT-large'\n    \n    NUM_CLASSES = 2\n\n    model, tokenizer = FastModel.from_pretrained(\n        model_name=model_name,\n        load_in_4bit=False,\n        max_seq_length=2048,\n        dtype=torch.bfloat16,\n        auto_model=AutoModelForSequenceClassification,\n        num_labels=NUM_CLASSES,\n        gpu_memory_utilization=0.8  # Reduce if out of memory\n    )\n\n    model = FastModel.get_peft_model(\n        model,\n        r=16,  # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n        # target_modules=[\n        #     \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n        #     \"gate_proj\", \"up_proj\", \"down_proj\", ],\n        lora_alpha=32,\n        lora_dropout=0,  # Supports any, but = 0 is optimized\n        bias=\"none\",  # Supports any, but = \"none\" is optimized\n        # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n        use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for very long context\n        random_state=3407,\n        use_rslora=False,  # We support rank stabilized LoRA\n        loftq_config=None,  # And LoftQ\n        task_type=\"SEQ_CLS\",\n    )\n\n    print(\"model parameters:\" + str(sum(p.numel() for p in model.parameters())))\n\n    # make all parameters trainable\n    # for param in model.parameters():\n    #     param.requires_grad = True\n\n    metric = evaluate.load(\"accuracy\")\n\n\n    def compute_metrics(eval_pred):\n        logits, labels = eval_pred\n        predictions = np.argmax(logits, axis=-1)\n        return metric.compute(predictions=predictions, references=labels)\n\n\n    def tokenize_function(examples):\n        # return tokenizer(examples['text'])\n        return tokenizer(examples['text'], max_length=512, truncation=True)\n\n\n    train_dataset = train_dataset.map(tokenize_function, batched=True)\n    val_dataset = val_dataset.map(tokenize_function, batched=True)\n    test_dataset = test_dataset.map(tokenize_function, batched=True)\n\n    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n    training_args = TrainingArguments(\n        per_device_train_batch_size=32,\n        gradient_accumulation_steps=1,\n\n        warmup_steps=10,\n        fp16=not torch.cuda.is_bf16_supported(),\n        bf16=torch.cuda.is_bf16_supported(),\n        optim=training_args.OptimizerNames.ADAMW_TORCH,\n        learning_rate=2e-5,\n        weight_decay=0.001,\n        lr_scheduler_type=\"linear\",\n        seed=3407,\n        num_train_epochs=3,  # bert-style models usually need more than 1 epoch\n        save_strategy=\"epoch\",\n\n        report_to=\"none\",\n\n        # group_by_length=True,\n        # eval_strategy=\"no\",\n        eval_strategy=\"no\",\n        eval_steps=0.25,\n        logging_strategy=\"steps\",\n        logging_steps=10,\n\n        label_names=[\"label\"],\n    )\n\n    from typing import Any, Dict, Tuple, Optional\n    class UnslothSafeTrainer(Trainer):\n        \"\"\"\n        安全的 prediction_step：**不** 调用 model.prediction_step（避免 unsloth 的 monkey-patch）。\n        直接使用 model(**inputs) 并提取 loss/logits/labels。\n        \"\"\"\n\n        def prediction_step(\n                self,\n                model,\n                inputs: Dict[str, Any],\n                prediction_loss_only: bool,\n                ignore_keys: Optional[Tuple[str]] = None,\n        ):\n            # 把 inputs 放到设备上（复用 Trainer 的内部方法）\n            inputs = self._prepare_inputs(inputs)\n\n            # 获取是否有 labels（有时 key 叫 labels，有时叫 label）\n            labels = None\n            if isinstance(inputs, dict):\n                labels = inputs.get(\"labels\", inputs.get(\"label\", None))\n\n            # 直接用 forward（不要调用 model.prediction_step）\n            with torch.no_grad():\n                outputs = model(**inputs)\n\n            # 解析 outputs：支持 dict 或 tuple\n            loss = None\n            logits = None\n\n            # 如果 model 返回 dict（huggingface 习惯），尽量取标准字段\n            if isinstance(outputs, dict):\n                # loss 可能在 outputs['loss']\n                loss = outputs.get(\"loss\", None)\n                # logits 可能在 outputs['logits'] 或 outputs['predictions']\n                logits = outputs.get(\"logits\", outputs.get(\"predictions\", None))\n            elif isinstance(outputs, tuple):\n                # tuple 常见格式: (logits, ...) 或 (loss, logits, ...)\n                if len(outputs) == 0:\n                    logits = None\n                elif len(outputs) == 1:\n                    logits = outputs[0]\n                elif len(outputs) == 2:\n                    # 一般 (loss, logits) 或 (logits, labels) —— 尝试智能判断\n                    a, b = outputs[0], outputs[1]\n                    # 若 a 是标量 tensor 且 b 不是标量，猜 a 是 loss\n                    if getattr(a, \"ndim\", None) == 0 or (isinstance(a, torch.Tensor) and a.numel() == 1):\n                        loss = a\n                        logits = b\n                    else:\n                        logits = a\n                else:\n                    # 常见 (loss, logits, ...) 或 (logits, ...)\n                    # 优先把第一个标量当 loss，第二个当 logits\n                    if getattr(outputs[0], \"ndim\", None) == 0 or (\n                            isinstance(outputs[0], torch.Tensor) and outputs[0].numel() == 1):\n                        loss = outputs[0]\n                        logits = outputs[1] if len(outputs) > 1 else None\n                    else:\n                        logits = outputs[0]\n\n            # 有时候 loss 在 outputs.loss，但未转到 cpu，保持 tensor\n            if prediction_loss_only:\n                # 只返回 loss 情况\n                return (loss, None, None)\n\n            # 确保 logits、labels 都在 cpu/device 上与 Trainer 期望一致\n            return (loss, logits, labels)\n\n    trainer = UnslothSafeTrainer(\n        model=model,\n        args=training_args,\n        processing_class=tokenizer,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics,\n    )\n\n    trainer_stats = trainer.train()\n\n    print(trainer_stats)\n\n    # model.eval()\n    # FastLanguageModel.for_inference(model)\n\n    prediction_outputs = trainer.predict(test_dataset)\n    print(prediction_outputs)\n    test_pred = np.argmax(prediction_outputs[0], axis=-1).flatten()\n    print(test_pred)\n\n    \n    os.makedirs(\"./result\", exist_ok=True)\n    result_output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred})\n    result_output.to_csv(\"./result/ModernBERT_unsloth.csv\", index=False, quoting=3)\n    logging.info('result saved!')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T02:43:47.545153Z","iopub.execute_input":"2025-11-19T02:43:47.545728Z","iopub.status.idle":"2025-11-19T05:25:37.912755Z","shell.execute_reply.started":"2025-11-19T02:43:47.545702Z","shell.execute_reply":"2025-11-19T05:25:37.911913Z"}},"outputs":[{"name":"stderr","text":"[colab_kernel_launcher.py|INFO]running /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py-f/root/.local/share/jupyter/runtime/kernel-7b1113cb-2514-48ce-8538-c8128e6f2974.json\n","output_type":"stream"},{"name":"stdout","text":"==((====))==  Unsloth 2025.11.3: Fast Modernbert patching. Transformers: 4.57.1.\n   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.9.0+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post1. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\nUnsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n","output_type":"stream"},{"name":"stderr","text":"Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Making `model.base_model.model.model` require gradients\nUnsloth: Upcasting `base_model.model.classifier` from float16 to float32 since it's in `modules_to_save`. Also allowing gradients.\nmodel parameters:403032068\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ea0bd19a4034d4599b751e7ffb6fd17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"256e9c514afa4db2948e783db4c48ee5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9147b063f07145f6bce483f09a3c6526"}},"metadata":{}},{"name":"stderr","text":"The model is already on multiple devices. Skipping the move to device specified in `args`.\n==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 20,000 | Num Epochs = 3 | Total steps = 1,875\nO^O/ \\_/ \\    Batch size per device = 32 | Gradient accumulation steps = 1\n\\        /    Data Parallel GPUs = 1 | Total batch size (32 x 1 x 1) = 32\n \"-____-\"     Trainable parameters = 7,198,722 of 403,032,068 (1.79% trained)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1875/1875 2:23:42, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>0.768300</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.734400</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.711800</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.696300</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.681800</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.681500</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.653400</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.626900</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.591100</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.545400</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.535800</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.494900</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.405800</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.390400</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.291200</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.279400</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.257900</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.170900</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.314300</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.208300</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.259700</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.226300</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.218300</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.221700</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.202600</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.168000</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.159400</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.146500</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.211900</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.165500</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.207400</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.167600</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.142800</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.141300</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.157700</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.143300</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.130000</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.175900</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.164900</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.116300</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.154300</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.217900</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.203100</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.133900</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.160700</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.136900</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.176600</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.173500</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.173100</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.168400</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>0.159000</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.185600</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.090300</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.123400</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.163800</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.155200</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.132000</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.146200</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.193300</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.122500</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.168500</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.148400</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.117900</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.153400</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.198300</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.116800</td>\n    </tr>\n    <tr>\n      <td>670</td>\n      <td>0.157400</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.130700</td>\n    </tr>\n    <tr>\n      <td>690</td>\n      <td>0.128300</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.145400</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>0.108600</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>0.146400</td>\n    </tr>\n    <tr>\n      <td>730</td>\n      <td>0.123800</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>0.136000</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.147700</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>0.128700</td>\n    </tr>\n    <tr>\n      <td>770</td>\n      <td>0.128400</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>0.162600</td>\n    </tr>\n    <tr>\n      <td>790</td>\n      <td>0.079600</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.123200</td>\n    </tr>\n    <tr>\n      <td>810</td>\n      <td>0.128200</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>0.166800</td>\n    </tr>\n    <tr>\n      <td>830</td>\n      <td>0.177700</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>0.215300</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.141800</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>0.105800</td>\n    </tr>\n    <tr>\n      <td>870</td>\n      <td>0.108000</td>\n    </tr>\n    <tr>\n      <td>880</td>\n      <td>0.123200</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>0.158900</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.109800</td>\n    </tr>\n    <tr>\n      <td>910</td>\n      <td>0.097800</td>\n    </tr>\n    <tr>\n      <td>920</td>\n      <td>0.115300</td>\n    </tr>\n    <tr>\n      <td>930</td>\n      <td>0.140900</td>\n    </tr>\n    <tr>\n      <td>940</td>\n      <td>0.134600</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.097400</td>\n    </tr>\n    <tr>\n      <td>960</td>\n      <td>0.158800</td>\n    </tr>\n    <tr>\n      <td>970</td>\n      <td>0.157600</td>\n    </tr>\n    <tr>\n      <td>980</td>\n      <td>0.175000</td>\n    </tr>\n    <tr>\n      <td>990</td>\n      <td>0.105500</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.138100</td>\n    </tr>\n    <tr>\n      <td>1010</td>\n      <td>0.065400</td>\n    </tr>\n    <tr>\n      <td>1020</td>\n      <td>0.124900</td>\n    </tr>\n    <tr>\n      <td>1030</td>\n      <td>0.119700</td>\n    </tr>\n    <tr>\n      <td>1040</td>\n      <td>0.182500</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.118800</td>\n    </tr>\n    <tr>\n      <td>1060</td>\n      <td>0.087100</td>\n    </tr>\n    <tr>\n      <td>1070</td>\n      <td>0.106000</td>\n    </tr>\n    <tr>\n      <td>1080</td>\n      <td>0.100500</td>\n    </tr>\n    <tr>\n      <td>1090</td>\n      <td>0.106500</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.110800</td>\n    </tr>\n    <tr>\n      <td>1110</td>\n      <td>0.146600</td>\n    </tr>\n    <tr>\n      <td>1120</td>\n      <td>0.145700</td>\n    </tr>\n    <tr>\n      <td>1130</td>\n      <td>0.143700</td>\n    </tr>\n    <tr>\n      <td>1140</td>\n      <td>0.155400</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.153800</td>\n    </tr>\n    <tr>\n      <td>1160</td>\n      <td>0.117900</td>\n    </tr>\n    <tr>\n      <td>1170</td>\n      <td>0.076400</td>\n    </tr>\n    <tr>\n      <td>1180</td>\n      <td>0.080800</td>\n    </tr>\n    <tr>\n      <td>1190</td>\n      <td>0.125400</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.101100</td>\n    </tr>\n    <tr>\n      <td>1210</td>\n      <td>0.108700</td>\n    </tr>\n    <tr>\n      <td>1220</td>\n      <td>0.108900</td>\n    </tr>\n    <tr>\n      <td>1230</td>\n      <td>0.150200</td>\n    </tr>\n    <tr>\n      <td>1240</td>\n      <td>0.125100</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.075400</td>\n    </tr>\n    <tr>\n      <td>1260</td>\n      <td>0.094900</td>\n    </tr>\n    <tr>\n      <td>1270</td>\n      <td>0.115900</td>\n    </tr>\n    <tr>\n      <td>1280</td>\n      <td>0.154700</td>\n    </tr>\n    <tr>\n      <td>1290</td>\n      <td>0.106400</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.150700</td>\n    </tr>\n    <tr>\n      <td>1310</td>\n      <td>0.116400</td>\n    </tr>\n    <tr>\n      <td>1320</td>\n      <td>0.111300</td>\n    </tr>\n    <tr>\n      <td>1330</td>\n      <td>0.113100</td>\n    </tr>\n    <tr>\n      <td>1340</td>\n      <td>0.135600</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>0.113800</td>\n    </tr>\n    <tr>\n      <td>1360</td>\n      <td>0.174900</td>\n    </tr>\n    <tr>\n      <td>1370</td>\n      <td>0.145300</td>\n    </tr>\n    <tr>\n      <td>1380</td>\n      <td>0.169800</td>\n    </tr>\n    <tr>\n      <td>1390</td>\n      <td>0.108700</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.157900</td>\n    </tr>\n    <tr>\n      <td>1410</td>\n      <td>0.118800</td>\n    </tr>\n    <tr>\n      <td>1420</td>\n      <td>0.136100</td>\n    </tr>\n    <tr>\n      <td>1430</td>\n      <td>0.103800</td>\n    </tr>\n    <tr>\n      <td>1440</td>\n      <td>0.086600</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>0.109300</td>\n    </tr>\n    <tr>\n      <td>1460</td>\n      <td>0.106500</td>\n    </tr>\n    <tr>\n      <td>1470</td>\n      <td>0.103700</td>\n    </tr>\n    <tr>\n      <td>1480</td>\n      <td>0.087400</td>\n    </tr>\n    <tr>\n      <td>1490</td>\n      <td>0.076600</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.170400</td>\n    </tr>\n    <tr>\n      <td>1510</td>\n      <td>0.067900</td>\n    </tr>\n    <tr>\n      <td>1520</td>\n      <td>0.143900</td>\n    </tr>\n    <tr>\n      <td>1530</td>\n      <td>0.062400</td>\n    </tr>\n    <tr>\n      <td>1540</td>\n      <td>0.075900</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>0.071900</td>\n    </tr>\n    <tr>\n      <td>1560</td>\n      <td>0.102600</td>\n    </tr>\n    <tr>\n      <td>1570</td>\n      <td>0.122000</td>\n    </tr>\n    <tr>\n      <td>1580</td>\n      <td>0.119400</td>\n    </tr>\n    <tr>\n      <td>1590</td>\n      <td>0.123200</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.069800</td>\n    </tr>\n    <tr>\n      <td>1610</td>\n      <td>0.108000</td>\n    </tr>\n    <tr>\n      <td>1620</td>\n      <td>0.163300</td>\n    </tr>\n    <tr>\n      <td>1630</td>\n      <td>0.084000</td>\n    </tr>\n    <tr>\n      <td>1640</td>\n      <td>0.127800</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>0.109200</td>\n    </tr>\n    <tr>\n      <td>1660</td>\n      <td>0.153800</td>\n    </tr>\n    <tr>\n      <td>1670</td>\n      <td>0.101800</td>\n    </tr>\n    <tr>\n      <td>1680</td>\n      <td>0.091100</td>\n    </tr>\n    <tr>\n      <td>1690</td>\n      <td>0.110700</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.065900</td>\n    </tr>\n    <tr>\n      <td>1710</td>\n      <td>0.137200</td>\n    </tr>\n    <tr>\n      <td>1720</td>\n      <td>0.157400</td>\n    </tr>\n    <tr>\n      <td>1730</td>\n      <td>0.094500</td>\n    </tr>\n    <tr>\n      <td>1740</td>\n      <td>0.148000</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>0.121700</td>\n    </tr>\n    <tr>\n      <td>1760</td>\n      <td>0.139100</td>\n    </tr>\n    <tr>\n      <td>1770</td>\n      <td>0.117300</td>\n    </tr>\n    <tr>\n      <td>1780</td>\n      <td>0.130600</td>\n    </tr>\n    <tr>\n      <td>1790</td>\n      <td>0.072000</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.089300</td>\n    </tr>\n    <tr>\n      <td>1810</td>\n      <td>0.141900</td>\n    </tr>\n    <tr>\n      <td>1820</td>\n      <td>0.090800</td>\n    </tr>\n    <tr>\n      <td>1830</td>\n      <td>0.099800</td>\n    </tr>\n    <tr>\n      <td>1840</td>\n      <td>0.090800</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>0.092900</td>\n    </tr>\n    <tr>\n      <td>1860</td>\n      <td>0.130300</td>\n    </tr>\n    <tr>\n      <td>1870</td>\n      <td>0.092000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"TrainOutput(global_step=1875, training_loss=0.172246222893397, metrics={'train_runtime': 8626.7986, 'train_samples_per_second': 6.955, 'train_steps_per_second': 0.217, 'total_flos': 6.472266916678886e+16, 'train_loss': 0.172246222893397, 'epoch': 3.0})\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"[root|INFO]result saved!\n","output_type":"stream"},{"name":"stdout","text":"PredictionOutput(predictions=array([[-4.0507812,  3.5214844],\n       [ 4.234375 , -4.0859375],\n       [ 0.8520508, -1.34375  ],\n       ...,\n       [ 2.9570312, -2.53125  ],\n       [-4.1132812,  2.7597656],\n       [-2.2851562,  1.9130859]], dtype=float32), label_ids=None, metrics={'test_runtime': 1011.5896, 'test_samples_per_second': 24.714, 'test_steps_per_second': 3.089})\n[1 0 0 ... 0 1 1]\n","output_type":"stream"}],"execution_count":7}]}